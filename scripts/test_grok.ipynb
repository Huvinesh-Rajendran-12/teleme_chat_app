{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient\n",
    "from http import HTTPStatus\n",
    "import json \n",
    "import dashscope\n",
    "from openai import AsyncOpenAI\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "XAI_API_KEY = os.getenv(\"XAI_API_KEY\", \"\")\n",
    "XAI_BASE_URL = os.getenv(\"XAI_BASE_URL\", \"\")\n",
    "DASHSCOPE_API_KEY = os.getenv(\"DASHSCOPE_API_KEY\", \"\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI(\n",
    "    base_url=XAI_BASE_URL,\n",
    "    api_key=XAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_temperature(location: str, unit: str = \"fahrenheit\"):\n",
    "    temperature: int\n",
    "    if unit.lower() == \"fahrenheit\":\n",
    "        temperature = 59\n",
    "    elif unit.lower() == \"celsius\":\n",
    "        temperature = 15\n",
    "    else:\n",
    "        raise ValueError(\"unit must be one of fahrenheit or celsius\")\n",
    "    return {\"location\": location, \"temperature\": temperature, \"unit\": \"fahrenheit\"}\n",
    "\n",
    "\n",
    "def get_current_ceiling(location: str):\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"ceiling\": 15000,\n",
    "        \"ceiling_type\": \"broken\",\n",
    "        \"unit\": \"ft\",\n",
    "    }\n",
    "\n",
    "tools_map = {\n",
    "    \"get_current_temperature\": get_current_temperature,\n",
    "    \"get_current_ceiling\": get_current_ceiling,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(url=QDRANT_URL)\n",
    "\n",
    "\n",
    "dashscope.base_http_api_url = 'https://dashscope-intl.aliyuncs.com/api/v1'\n",
    "\n",
    "def embed_with_str(query: str):\n",
    "    resp = dashscope.TextEmbedding.call(\n",
    "        model=dashscope.TextEmbedding.Models.text_embedding_v3,\n",
    "        api_key=DASHSCOPE_API_KEY,\n",
    "        input=query)\n",
    "    if resp.status_code == HTTPStatus.OK:\n",
    "        return resp.output['embeddings'][0]['embedding']\n",
    "    else:\n",
    "        print(resp)\n",
    "\n",
    "def search_knowledge_base(query: str) -> Tuple[List[Dict[str, Any]], str]:\n",
    "    \"\"\"\n",
    "    Search the knowledge base for relevant information.\n",
    "\n",
    "    Args:\n",
    "        query: str -> query used to retrieve the relevant information.\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        1. List of the formatted results with title, content preview, and source link\n",
    "        2. String joining all relevant information from results\n",
    "    \"\"\"\n",
    "\n",
    "    embed = embed_with_str(query)\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"knowledge_base_collection\",\n",
    "        query=embed,\n",
    "        with_payload=True,\n",
    "        limit=3,\n",
    "        score_threshold=0.6\n",
    "    )\n",
    "    formatted_results = []\n",
    "    combined_text_parts = []\n",
    "    for result in results.points:\n",
    "        # Format dictionary result\n",
    "        content_preview = result.payload[\"content\"][:200] + \"...\" if len(result.payload[\"content\"]) > 200 else result.payload[\"content\"]\n",
    "        formatted_results.append({\n",
    "            \"title\": result.payload[\"title\"],\n",
    "            \"content_preview\": content_preview,\n",
    "            \"source_link\": result.payload[\"source_link\"],\n",
    "            \"relevance_score\": round(result.score, 3)\n",
    "        })\n",
    "\n",
    "        # Add to combined text\n",
    "        combined_text_parts.append(\n",
    "            f\"Title: {result.payload['title']}\\n\"\n",
    "            f\"Content: {result.payload['content']}\\n\"\n",
    "            f\"Source: {result.payload['source_link']}\\n\"\n",
    "        )\n",
    "\n",
    "    combined_text = \"\\n\".join(combined_text_parts)\n",
    "    return formatted_results, combined_text\n",
    "\n",
    "def search_doctors(query: str) -> Tuple[List[Dict[str, Any]], str]:\n",
    "    \"\"\"\n",
    "    Search for doctors based on query.\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        1. List of formatted results with doctor information\n",
    "        2. String joining all relevant information from results\n",
    "    \"\"\"\n",
    "    embed = embed_with_str(query)\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"doctor_collection\",\n",
    "        query=embed,\n",
    "        with_payload=True,\n",
    "        limit=3,\n",
    "        score_threshold=0.5,\n",
    "    )\n",
    "\n",
    "    formatted_results = []\n",
    "    combined_text_parts = []\n",
    "\n",
    "    for result in results.points:\n",
    "        # Format dictionary result\n",
    "        formatted_results.append({\n",
    "            \"doctor_name\": result.payload[\"doctor_name\"],\n",
    "            \"specialization\": result.payload[\"doctor_field\"],\n",
    "            \"description\": result.payload[\"doctor_description\"],\n",
    "            \"availability_status\": \"Available\" if result.payload[\"availability\"] else \"Not Available\",\n",
    "            \"appointment_link\": result.payload[\"appointment_link\"],\n",
    "            \"relevance_score\": round(result.score, 3)\n",
    "        })\n",
    "\n",
    "        # Add to combined text\n",
    "        combined_text_parts.append(\n",
    "            f\"Specialization: {result.payload['doctor_field']}\\n\"\n",
    "            f\"Description: {result.payload['doctor_description']}\\n\"\n",
    "        )\n",
    "\n",
    "    combined_text = \"\\n\".join(combined_text_parts)\n",
    "    return formatted_results, combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_definition = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_knowledge_base\",\n",
    "            \"description\": \"Retrieve health information from the knowledge base given the query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The user query, e.g. what is diabetes ?\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_doctors\",\n",
    "            \"description\": \"Get the suitalbe doctors based on the user's query.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The user query, e.g. recommend me a doctor for diabetes\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "tools_map = {\n",
    "    \"search_knowledge_base\": search_knowledge_base,\n",
    "    \"search_doctors\": search_doctors,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "global messages\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Hi, what is acne ?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def get_next_questions(last_message: str):\n",
    "    \"\"\"Based on the last message get suggestions for follow up questions.\"\"\"\n",
    "    try:\n",
    "        prompt = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Based on this health-related response: \"{last_message}\"\n",
    "            Suggest 2 natural follow-up questions that a patient might want to ask.\n",
    "            These should be within 4 four words.\n",
    "            Return ONLY the questions in a Python list format like this: [\"question 1\", \"question 2\"]\n",
    "            The questions should be clear and concise.\"\"\"\n",
    "        }\n",
    "        response = await client.chat.completions.create(\n",
    "            model=\"grok-2-1212\",\n",
    "            messages=[prompt],\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        suggestions_text = response.choices[0].message.content\n",
    "        import ast\n",
    "        try:\n",
    "            suggestions = ast.literal_eval(suggestions_text)\n",
    "            if isinstance(suggestions, list) and len(suggestions) > 0:\n",
    "                return suggestions[:2]  # Ensure we only get 2 questions\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return [\"Could you explain more about that?\",\n",
    "                \"Summarize this\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating suggestions: {e}\")\n",
    "        return [\"Could you explain more about that?\",\n",
    "                \"Summarize this\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def routerLLM(tools_definition, user_msg, assistant_msg=None):\n",
    "    try:\n",
    "        if assistant_msg:\n",
    "            prompt = f\"\"\"\n",
    "            Tools definition: {tools_definition}.\\n\n",
    "\n",
    "            Based on the previous assistant message : {assistant_msg} and \n",
    "            the current user query : {user_msg} determine if any of the tools\n",
    "            in the tools definition should be used or not. \n",
    "\n",
    "            Rules for tool selection: \n",
    "            1. The 'search_knowledge_base' tool:\n",
    "                - Use when health related information needs to be retrieved to answer the user query. \n",
    "                - The user query should be a new query and not a follow up to the previous assistant answer.\n",
    "\n",
    "            2. The 'search_doctors' tool:\n",
    "                - Use when the user wants to consult or asking for a doctor recommendation.  \n",
    "            Provide your response in the following JSON format:\n",
    "                {{\n",
    "                    \"requires_tool\": true/false,\n",
    "                    \"tool_name\": \"name of tool if required, null if not\",\n",
    "                    \"reason\": \"detailed explanation of why the tool is needed or not\",\n",
    "                    \"args\": {{\n",
    "                        \"query\": The user query used to retrieve information from the necessary tool.\n",
    "                    }}\n",
    "                }}\n",
    "\n",
    "            Important:\n",
    "            - Only return a valid JSON object\n",
    "            - Don't include the actual content/code in the response\n",
    "            - Be decisive - either a tool is needed or it isn't\n",
    "            - Consider the context from the previous assistant message\n",
    "            \"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"\n",
    "            Tools definition: {tools_definition}.\\n\n",
    "\n",
    "            Based on the user query : {user_msg} determine if any of the tools\n",
    "            in the tools definition should be used or not. \n",
    "\n",
    "            Rules for tool selection: \n",
    "            1. The 'search_knowledge_base' tool:\n",
    "                - Use when health related information needs to be retrieved to answer the user query. \n",
    "                - If the user query is not health related, DO NOT use this tool.\n",
    "\n",
    "            2. The 'search_doctors' tool:\n",
    "                - Use when the user wants to consult or asking for a doctor recommendation.  \n",
    "\n",
    "            Provide your response in the following JSON format:\n",
    "                {{\n",
    "                    \"requires_tool\": true/false,\n",
    "                    \"tool_name\": \"name of tool if required, null if not\",\n",
    "                    \"reason\": \"detailed explanation of why the tool is needed or not\",\n",
    "                    \"args\": {{\n",
    "                        \"query\": The user query used to retrieve information from the necessary tool.\n",
    "                    }}\n",
    "                }}\n",
    "        \n",
    "            Important:\n",
    "            - Only return a valid JSON object\n",
    "            - Don't include the actual content/code in the response\n",
    "            - Be decisive - either a tool is needed or it isn't\n",
    "            \"\"\"\n",
    "\n",
    "        response = await client.chat.completions.create(\n",
    "            model=\"grok-2-1212\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        json_content = result.strip().strip('```json').strip('```')\n",
    "        print(json_content)\n",
    "        json_result = json.loads(json_content)\n",
    "        return json_result\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "    \"requires_tool\": true,\n",
      "    \"tool_name\": \"search_doctors\",\n",
      "    \"reason\": \"The user's query 'doctor for acne' indicates a need for a doctor recommendation specifically for acne, which aligns with the purpose of the 'search_doctors' tool. This query is a direct request for a recommendation and not a follow-up to the previous assistant message about the definition of acne.\",\n",
      "    \"args\": {\n",
      "        \"query\": \"doctor for acne\"\n",
      "    }\n",
      "}\n",
      "\n",
      "{'requires_tool': True, 'tool_name': 'search_doctors', 'reason': \"The user's query 'doctor for acne' indicates a need for a doctor recommendation specifically for acne, which aligns with the purpose of the 'search_doctors' tool. This query is a direct request for a recommendation and not a follow-up to the previous assistant message about the definition of acne.\", 'args': {'query': 'doctor for acne'}}\n"
     ]
    }
   ],
   "source": [
    "result = await routerLLM(tools_definition, \"doctor for acne\", assistant_msg=\"Acne is a form of inflammatory skin on the face.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user message recommend me a doctor for eye sight\n",
      "assistant message Based on the available information, I recommend Dr. Azlina Firzah, who specializes in Endocrinology and is currently available for appointments. Endocrinologists often deal with metabolic issues, including those related to weight management. You can book an appointment with her through this link: [Appointment with Dr. Azlina Firzah](https://www.pantai.com.my/kuala-lumpur/ms/appointment/azlina-firzah-bt-abd-aziz).\n",
      "\n",
      "If you are specifically looking for a doctor focused on weight loss and Dr. Vijay Ananda Paramasvaran becomes available, he might be a good choice as well, given his specialization in endocrinology, which often includes managing conditions related to weight. Keep an eye on his availability status at this link: [Appointment with Dr. Vijay Ananda Paramasvaran](https://www.pantai.com.my/kuala-lumpur/appointment/vijay-ananda-paramasvaran).\n",
      "\n",
      "{\n",
      "    \"requires_tool\": true,\n",
      "    \"tool_name\": \"search_doctors\",\n",
      "    \"reason\": \"The user is asking for a doctor recommendation specifically for eye sight issues. The 'search_doctors' tool is appropriate as it is designed to find suitable doctors based on the user's query, which in this case is a request for a doctor specializing in eye care.\",\n",
      "    \"args\": {\n",
      "        \"query\": \"recommend me a doctor for eye sight\"\n",
      "    }\n",
      "}\n",
      "\n",
      "[{'doctor_name': 'Dr Hoh Hon Bing', 'specialization': 'Ophthalmology', 'description': 'Dr Hoh Hon Bing is an Ophthalmologist, who is trained to diagnose and treat all eye and visual problems including vision services (glasses and contacts) and provide treatment and prevention of medical disorders of the eye including surgery.', 'availability_status': 'Available', 'appointment_link': 'https://www.pantai.com.my/kuala-lumpur/appointment/hoh-hon-bing', 'relevance_score': 0.662}, {'doctor_name': 'Dr Vijay Ananda Paramasvaran', 'specialization': 'Endocrinology', 'description': 'Dr Vijay Ananda Paramasvaran specializes in diabetics diagnosis and treatment. ', 'availability_status': 'Not Available', 'appointment_link': 'https://www.pantai.com.my/kuala-lumpur/appointment/vijay-ananda-paramasvaran', 'relevance_score': 0.518}]\n",
      "For issues related to eyesight, I recommend Dr. Hoh Hon Bing, who is an Ophthalmologist specializing in diagnosing and treating all eye and visual problems, including vision services and surgical treatments. Dr. Hoh Hon Bing is currently available for appointments. You can book an appointment with him through this link: [Appointment with Dr. Hoh Hon Bing](https://www.pantai.com.my/kuala-lumpur/appointment/hoh-hon-bing).For issues related to eyesight, I recommend Dr. Hoh Hon Bing, who is an Ophthalmologist specialized in diagnosing and treating all eye and visual problems, including vision services and surgical treatments. Dr. Hoh Hon Bing is currently available for appointments. You can book an appointment with him through this link: [Appointment with Dr. Hoh Hon Bing](https://www.pantai.com.my/kuala-lumpur/appointment/hoh-hon-bing).\n",
      "\n",
      "suggestions [\"What's the consultation fee?\", 'Is insurance accepted?']\n"
     ]
    }
   ],
   "source": [
    "if messages[-1]['role'] == 'user':\n",
    "    usr_msg = messages[-1]['content']\n",
    "    if len(messages) > 1 and messages[-2]['role'] == 'assistant':\n",
    "        assistant_msg = messages[-2]['content']\n",
    "    else:\n",
    "        assistant_msg = None\n",
    "\n",
    "    print('user message', usr_msg)\n",
    "    print('assistant message', assistant_msg)\n",
    "    route = await routerLLM(tools_definition, usr_msg, assistant_msg)\n",
    "\n",
    "    if route['requires_tool']:\n",
    "        fn_name = route['tool_name']\n",
    "        fn_args = route['args']\n",
    "        result, _ = tools_map[fn_name](**fn_args)\n",
    "        print(result)\n",
    "\n",
    "        # prompt = f\"\"\"\n",
    "        #     User query: {usr_msg}\n",
    "        #     Retrieved data: {result}\n",
    "        # \"\"\"\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": json.dumps(result),\n",
    "                \"tool_name\": fn_name\n",
    "            }\n",
    "        )\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"grok-2-1212\",\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    fn_call_in_progress = False\n",
    "    fn_results = []\n",
    "\n",
    "    async for chunk in response:\n",
    "\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "        if chunk.choices[0].delta.tool_calls:\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            for tool_call in chunk.choices[0].delta.tool_calls:\n",
    "\n",
    "                fn_name = tool_call.function.name\n",
    "                fn_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "\n",
    "                result = tools_map[fn_name](**fn_args)\n",
    "\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"content\": json.loads(result),\n",
    "                        \"tool_name\": fn_name,\n",
    "                        \"tool_call_id\": tool_call.id  # tool_call.id supplied in Grok's response\n",
    "                    }\n",
    "                )\n",
    "\n",
    "if messages[-1]['role'] == 'tool':\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"grok-2-1212\",\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    async for chunk in response:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            messages[-1]['content'] += chunk.choices[0].delta.content \n",
    "            print(chunk.choices[0].delta.content, end=\"\", flush=True)  \n",
    "\n",
    "if messages[-2]['role'] == 'tool' and messages[-1]['role'] == 'assistant':\n",
    "    print(\"\\n\")\n",
    "    suggestions = await get_next_questions(messages[-1]['content'])\n",
    "    print('suggestions', suggestions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    'role': 'user',\n",
    "    'content': 'recommend me a doctor for eye sight'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
